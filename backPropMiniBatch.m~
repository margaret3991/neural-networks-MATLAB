function [W1, b1, W2, b2, mseValues] = backPropMiniBatch(trainInputs, trainTargets, learningRate, iterations, batchFraction)
%   ------- BACKPROPAGATION FUNCTION -------
%   
%   INPUTS:
%   trainInputs = input vector for training set 
%   trainTargets = target vector for training set
%   learning rate = alpha learning rate 
%   iterations = set value for maximum iterations 
%   batchFraction = fraction for making the mini-batches  
%       Ex batchFraction = 10 means batch size will be 1/10 of training set 

%   transfer function definitions (HARDCODED):
%   layer1 function: logsigmoid()
%   layer2 function: logsigmoid()

%   OUTPUTS:
%   W1 = updated weight matrix for layer 1
%   b1 = updated bias vector for layer 1
%   W2 = updated weight matrix for layer 2
%   b2 = updated bias vector for layer 2
%   mseValues = vector of average MSE for each epoch 

% HIDDEN LAYER SIZE HARDCODED HERE 
hiddenLayer = 15;

% get size of target space to determine output layer size 
[targR, targC] = size(trainTargets);
outputRows = targR;

batchSize = targC/batchFraction;

%   Initial Weights and Biases created using small random values  
[trainRows, trainCols] = size(trainInputs);

% ---- Layer 1 ----- %
W1 = zeros(hiddenLayer, trainRows); %creates empty weight matrix
b1 = rand(hiddenLayer, 1);
for m = 1:hiddenLayer
    for n = 1:trainRows
        W1(m,n) = rand(1)/10;
    end
end

% ---- Layer 2 ----- %
%[w1r w1c] = size(W1);
W2 = zeros(outputRows, hiddenLayer);
b2 = rand(outputRows, 1);

for m = 1:outputRows
    for n = 1:hiddenLayer
        W2(m,n) = rand(1)/10;
        %b2(m) = rand(1)/10;
    end
end


alpha = learningRate;
mseIter = 1;    %just a start value for the while loop 
iters = 1;      %iteration counter 
mseValues = zeros(iterations, 1);   %initialize MSE vector 

% outside loop controls the training iterations 
while( mseIter > 0.0005 && iters < iterations + 1)
    
    mseIter = 0; % cumulative MSE variable for training iteration
    
    for batch = 1:batchFraction
        % insert batch code here
        
        accS1 = zeros(hiddenLayer, 1);
        accS2 = zeros(outputRows, 1);
        F2n2 = zeros(outputRows, outputRows);
        F1n1 = zeros(hiddenLayer, hiddenLayer);
        for batchPass = (1 + ((batch - 1) * batchSize)):((batch) * (batchSize))
            % inner batch loop
            % disp(batchPass) 
            % get input and target from their matrices 
            input = trainInputs(:, batchPass);
            target = trainTargets(:, batchPass);

            %------ Now Propagate Forwards ------%
            a1 = logSigmoid((W1 * input) + b1);

            a2 = logSigmoid((W2 * a1) + b2);

            error = target - a2; % error vector 
            mseIter = mseIter + mse(target, a2); % add this pair's MSE

            %------ Now Calculate Sensitivities and Backpropagate ------%

            % create and populate the f2(n2) derivative matrix 
            
            for i = 1:outputRows
                for j = 1:outputRows
                    if i == j
                        F2n2(i,j) = (1 - a2(i,1))*(a2(i,1));
                    end
                end
            end

            % calculate first sensitivity s^M
            s2 = -2 * F2n2 * error;  % creates vector sized outputRows x 1
            accS2 = accS2 + s2;
            
            % create and populate the f1(n1) derivative matrix
            
            [f1rows f1cols] = size(F1n1);
            for i = 1:f1rows
                for j = 1:f1cols
                    if i == j
                        F1n1(i,j) = (1 - a1(i,1))*(a1(i,1));
                    end
                end
            end

            % calculate next layer's sensitivity s^M-1
            s1 = F1n1 * W2' * s2; %creates vector hiddenLayer x 1 sized 
            accS1 = accS1 + s1
        end
        
        
        %------ Update Weights and Biases after each Batch ------%

        W2 = W2 - (alpha * accS2 * a1');
        b2 = b2 - (alpha * accS2);

        W1 = W1 - (alpha * accS1 * input');
        b1 = b1 - (alpha * accS1);
        
    end

    mseIter = mseIter/targC; % get the average for the epoch
    mseValues(iters, 1) = mseIter; % save it to output array 
    iters = iters + 1; % update iters for while loop control 
end

end